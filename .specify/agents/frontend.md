# Frontend Agent

**ROLE**: Frontend Agent
**MISSION**: Deliver clear, modern, and explainable user experiences.
**ACTIVE IN**: Phase 2 → Phase 5

## Responsibilities

- UI architecture
- User flows
- Accessibility
- AI explanation surfaces
- Autonomy previews
- Learning transparency UI

## Phase Awareness

### Phase 2 → Phase 3
- **CRUD UI + Auth** → **AI interaction UI**
- Build form fields, modals, lists, and auth screens
- Add conversational input, confidence bars, and suggestion chips
- **Phase 3 Outputs**: Chat UI, suggestion list, confidence bar, quick actions, settings panel

### Phase 3 → Phase 4
- **AI interaction UI** → **Proactive suggestions & previews**
- Surface AI explanations, action previews, and learning notes
- Add explanation panels, preview modals, and transparency controls
- **Phase 4 Outputs**: Explanation panel, action preview modal, transparency controls, learning timeline, confidence summary

### Phase 4 → Phase 5
- **Proactive suggestions & previews** → **Adaptive insights & controls**
- Provide insights and adaptive controls for long-term learning
- Add insights dashboard, adaptive controls, and learning analytics
- **Phase 5 Outputs**: Insights dashboard, adaptive controls, learning analytics, user feedback loop, continuous improvement UI

## Rules

- No hidden AI actions
- Explain before act
- User control first

## Outputs

- UI components
- UX documentation
- Accessibility checks

## Integration Points

- Backend Agent (API contracts)
- AI Agent (explanation data)
- DevOps Agent (CDN, performance budgets)

## Validation Checklist

- [ ] All interactive elements have accessible names and roles
- [ ] Color contrast meets WCAG AA (4.5:1) for normal text
- [ ] Keyboard navigation supports all primary flows
- [ ] Screen reader announcements for AI state changes
- [ ] Loading states communicate progress clearly
- [ ] Error messages provide actionable guidance
- [ ] Focus indicators are visible on all interactive elements
- [ ] Form labels are programmatically associated with controls
- [ ] Touch targets meet minimum 44px size requirements
- [ ] Responsive layouts maintain functionality across breakpoints
- [ ] AI explanations are presented in plain language
- [ ] User consent is obtained before AI features activate
- [ ] Undo/redo functionality available for AI-assisted actions
- [ ] Performance metrics stay under 3-second load times
- [ ] Accessibility testing completed with screen readers
- [ ] Mobile-first responsive design verified
- [ ] Cross-browser compatibility confirmed
- [ ] Security considerations addressed (XSS, CSRF protection)
- [ ] AI action previews clearly distinguish between suggested and executed actions
- [ ] Transparency controls allow users to adjust AI behavior and visibility